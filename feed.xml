<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title></title>
    <description></description>
    <link>/</link>
    <atom:link href="/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Tue, 22 Feb 2022 13:55:26 +0000</pubDate>
    <lastBuildDate>Tue, 22 Feb 2022 13:55:26 +0000</lastBuildDate>
    <generator>Jekyll v4.1.1</generator>
    
      <item>
        <title>資料倉儲歷史</title>
        <description>&lt;h2 id=&quot;mpp-小歷史&quot;&gt;MPP 小歷史&lt;/h2&gt;

&lt;p&gt;MPP(Massively Parallel Processing)，大規模並行處理，指的是將任務分散到多個節點上，各自計算完成後在合併結果。當談論到
MPP的時候，我們一般指的都是分佈式數據庫(MPP RDBMS)，例如 Teradata。為了能將節點們各自獨立並能更好的拓展性能，MPP 架構
採用 shared-nothing 的概念，不共享存儲和計算資源。資料也以sharding的方式儲存在各個節點。&lt;/p&gt;

&lt;p&gt;Hadoop 被設計成從單個服務器擴展到數千臺，每臺機器(節點)都提供本地計算和存儲。
Hadoop 本身的設計目的不是依靠硬體來提供高可用性，而是在應用層檢測和處理故障，從而在節點上提供高可用性服務，
每個節點都可能發生故障。它包括 Hadoop Common，Hadoop Distributed File System(hdfs)，Hadoop YARN，Hadoop
MapReduce。工作場合上，Hadoop 常常被拿來和 MPP RDBMS 比較，&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;MPP RDBMS 只能處理結構化數據，而 Hadoop 則處理的大部分是非結構化資料。當然 Hadoop也處理結構化資料，Hive就是 Hadoop
生態圈的資料倉儲解決方案。&lt;/li&gt;
  &lt;li&gt;Hadoop以資料塊(block)的方式儲存數據，預設的大小是 128MB，比作業系統裡面的塊概念要大很多(作業系統塊大小是 4KB)，
可以根據實際需求修改 HDFS 塊大小的設定。而 RDBMS 則是將資料保存在本地的 file system 上，並根據不同大小的 page size
設定 (4k, 8k, 16k…)，會有不同的欄位個數或資料大小限制。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Spark&lt;/p&gt;

&lt;p&gt;資料倉儲理論和Spark的架構
SPARK与具体存储解耦，采用的是与shared-nothing MPP数据库不同的“计算与存储分离”的架构，可提供更具弹性的部署方式，
既能独立部署运行，也能够与HDFS集成。&lt;/p&gt;

&lt;h3&gt;#&lt;/h3&gt;

&lt;h3 id=&quot;-1&quot;&gt;#&lt;/h3&gt;

&lt;h3 id=&quot;-reference&quot;&gt;# Reference&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://cloud.tencent.com/developer/article/1544733&quot;&gt;Hadoop vs MPP&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.gushiciku.cn/pl/a2vN/zh-hk&quot;&gt;MPP架構與Hadoop架構是一回事嗎？&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://medium.com/@jockeyng/hadoop與mpp是什麼關係-有什麼區別和聯繫-afb4397e12a1&quot;&gt;Hadoop與MPP是什麼關係?有什麼區別和聯繫?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://toutiao.io/posts/2a9ayg/preview&quot;&gt;MPP 的进化：深入理解 Batch 和 MPP 优缺点&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.linkedin.com/pulse/hadoop-vs-rdbms-storage-performance-design-gautam-prothia&quot;&gt;https://www.linkedin.com/pulse/hadoop-vs-rdbms-storage-performance-design-gautam-prothia&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.yinxiang.com/everhub/note/4e0c04c8-1167-4c3e-8c1d-52307f782745&quot;&gt;数据平台发展简史 - 从“shared-nothing MPP”到云上“Multi-Cluster shared-data”&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/flyinthesky111/article/details/113558863&quot;&gt;浅谈Hadoop体系和MPP体系&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.zhihu.com/question/27589901&quot;&gt;mpp架构是什么？它与各种sql on hadoop架构根本区别在那里，优点和缺点是什么？求专业人士赐教？&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://mentalmodels4life.net/2016/08/14/apache-spark-vs-mpp-databases/&quot;&gt;Apache Spark vs MPP Databases&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://saintbacchus.github.io/2019/06/14/并行计算模式/&quot;&gt;并行计算模式&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Tue, 25 Jan 2022 00:00:00 +0000</pubDate>
        <link>/%E6%8A%80%E8%A1%93/2022/01/25/%E8%B3%87%E6%96%99%E5%80%89%E5%84%B2%E6%AD%B7%E5%8F%B2/</link>
        <guid isPermaLink="true">/%E6%8A%80%E8%A1%93/2022/01/25/%E8%B3%87%E6%96%99%E5%80%89%E5%84%B2%E6%AD%B7%E5%8F%B2/</guid>
        
        
        <category>技術</category>
        
      </item>
    
      <item>
        <title>Elasticsearch Removal Of Mapping Types</title>
        <description>&lt;p&gt;–
layout: post
title: “ElasticSearch Removal of mapping types”
subtitle: “”
date: 2021-12-30
categories: [技術]
—&lt;/p&gt;

&lt;p&gt;正好遇到舊叢集升版本，當然 ElasticSearch 的版本也升級了，從 6.1 升級到了 7.13，導致原來有些程式的邏輯需要更新。
其中有一個就是 ElasticSearch 索引中的每個文檔不再接受一個自己定義的 mapping type (_type) 了，所有的document的
預設的 mapping type 都是 _doc，並且也不需要一個欄位來特別表示了。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Before 7.0.0, the mapping definition included a type name. Elasticsearch 7.0.0 and later no longer 
accept a default mapping.&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;-tldr&quot;&gt;# TL;DR&lt;/h3&gt;

&lt;p&gt;好處&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;將有不同schema的資料儲存在同一個索引中，可能會導致資料太稀疏或者干擾到Lucene壓縮資料的效能;&lt;/li&gt;
  &lt;li&gt;獨立的索引，可以避免一個相同field名稱，但是卻需要有不同資料類型的囧境發生，因為一個索引裡面的相同名字的欄位的
資料型態必須要是一致的;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;如果還是需要類似原來一個 document mapping types 的功能，可以嘗試下面幾種做法:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;一個索引裡面都是相同的 document type，簡單來說就是把索引涵蓋的資料範圍縮小;&lt;/li&gt;
  &lt;li&gt;或者自己模擬一個 type 欄位，這個方法會使得在一個索引裡面有不同 schema 的資料;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;在7.0.0版本之前的 ElasticSearch 如果要模擬文檔之間的一對多 Parent/Child 關係，會在同一個index裡面定義兩個自定義
 mapping type ，分別表示 parent 和 child。但是如果把 _doc 欄位砍掉，Parent/Child 關係就不能這樣子建立了。所以，
就有了新的 join 類型的欄位出現。&lt;/p&gt;

&lt;h3 id=&quot;-reference&quot;&gt;# Reference&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://godleon.github.io/blog/Elasticsearch/Elasticsearch-getting-started/&quot;&gt;小信豬的原始部落&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.elastic.co/guide/en/elasticsearch/reference/current/removal-of-types.html&quot;&gt;Removal of mapping types&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Thu, 30 Dec 2021 00:00:00 +0000</pubDate>
        <link>/2021/12/30/ElasticSearch-Removal-of-mapping-types/</link>
        <guid isPermaLink="true">/2021/12/30/ElasticSearch-Removal-of-mapping-types/</guid>
        
        
      </item>
    
      <item>
        <title>Spark程式在獲取Kerberos ticket</title>
        <description>&lt;p&gt;最近盤點在Hadoop叢集上跑的Spark批次程式，&lt;del&gt;你才會發現有些東西放在那邊遲早有一天會臭掉&lt;/del&gt;，如果沒有寫下來也不會知道這些
程式是怎麼取得Kerberos認證的。因為在執行一些運行時間較長的 Spark ETL 任務的時候會遇到 Kerberos token 的認證過期，
所以才會有這篇文章想要弄清楚 Spark 取得 Kerberos 認證的來龍去脈。具體碰到的情況是HDFS_DELEGATION_TOKEN在Spark
應用程式執行的第7天就會過期，但經過排除這個只是 Hadoop 的一個bug， 只要把 Hadoop 更新到 2.9 之後的版本就不會有問題了，
在另外一篇文章有提到。
所以基本上會需要排除找 Spark Application 的 Kerberos token 過期時間和前面這個問題之間的關係，問題混在一起完全會抓不到重點。&lt;/p&gt;

&lt;h3 id=&quot;-spark-application-with-kerberos&quot;&gt;# Spark Application with Kerberos&lt;/h3&gt;

&lt;p&gt;查找資料後，發現 Spark 應用程式在執行的時候
會根據下面 3 個文件和 Kerberos KDC server 交互取得在 Hadoop 叢集上執行任務的認證。所以，Spark 應用程式取得的token
的有效期限到底是多長？以及Spark會自動根據使用者指定的Kerberos keytab位置，和特定的 principle，keytab去更新 token 嗎？&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Spark Application eats Kerberos credential cache (KRB5CCNAME) 
KRB5CCNAME environment variable must be set by your Java, it’s set automatically after logon to the
credential cache file. It’s default path is /tmp/krb5cc_$(id -u)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;krb5.conf 儲存 kdc 服務器的相關配置。By default, krb5.conf should be in the same directory on every
host in your cluster, the default location is /etc/krb5.conf , or you should specify by setting 
spark.driver.extraJavaOptions and spark.executor.extraJavaOptions, 
with -Djava.security.krb5.conf=/path/to/krb5.conf&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;keytab，用于存储资源主体的身份验证凭据，它可以包含principals和它們對應的加密principal key&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;另外，Spark 獲取的 Kerberos token最長有效期限是，由下面五個設定的最小值決定。上面的幾個不同地方的設定的名稱如下，
實踐上也確實符合預期，把前面幾個設定值得大小都調大之後 kinit 還是無法獲得較長時間的 maximum renewable life，
還是需要調整 krbtgt 的 max lifetime。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-angular2html&quot;&gt;
1. kinit -l 10h -r 7d, 舉例而言，一個 maximum ticket life 10小時，maximum renewable life 7 天的 ticket；
2. /etc/krb5.conf, ticket_lifetime
3. Principal 的 maximum ticket life time
4. kerberos Server上, /var/kerberos/krb5kdc/kdc.conf 設定 max_life 
5. (Microsoft) krbtgt 帳號的 max lifetime

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;-reference&quot;&gt;# Reference&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.ibm.com/docs/en/spectrum-conductor/2.5.1?topic=group-submitting-spark-batch-applications-kerberos-authentication&quot;&gt;Submitting Spark batch applications with Kerberos authentication
&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://github.com/LucaCanali/Miscellaneous/blob/master/Spark_Notes/Spark_Executors_Kerberos_HowTo.md&quot;&gt;HowTo: Enable Spark executors to access Kerberized resources
&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://stackoverflow.com/questions/14682153/lifetime-of-kerberos-tickets&quot;&gt;Lifetime of Kerberos tickets&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.twblogs.net/a/5b885ca02b71775d1cdbeed1&quot;&gt;Kerberos ticket lifetime-大數據姐姐&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://help.aliyun.com/document_detail/256357.htm&quot;&gt;配置Kerberos认证&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Thu, 23 Dec 2021 00:00:00 +0000</pubDate>
        <link>/%E6%8A%80%E8%A1%93/2021/12/23/Spark%E7%A8%8B%E5%BC%8F%E5%9C%A8%E7%8D%B2%E5%8F%96Kerberos-ticket/</link>
        <guid isPermaLink="true">/%E6%8A%80%E8%A1%93/2021/12/23/Spark%E7%A8%8B%E5%BC%8F%E5%9C%A8%E7%8D%B2%E5%8F%96Kerberos-ticket/</guid>
        
        
        <category>技術</category>
        
      </item>
    
      <item>
        <title>記一次HDFS_DELEGATION_TOKEN過期的問題</title>
        <description>&lt;p&gt;TL;DR &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-9276&quot;&gt;HDFS-9276&lt;/a&gt;, &lt;a href=&quot;https://github.com/apache/spark/pull/9168&quot;&gt;SPARK-11182&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;最近開發的Spark Streaming串流程式每七天就會報下面這串 Exception，起初也不以為意覺得是Hadoop叢集的問題，
後來觀察日誌才發現它是每七天就會出現一次，讓程式 crash 掉的問題。可以理解為，每七天Spark的HDFS_DELEGATION_TOKEN
就會失效，也就聯想到Hadoop叢集的 namenode delegation token 的最大lifetime的初始值也是7天。
(dfs.namenode.delegation.token.max-lifetime=604800000ms) and dfs.namenode.delegation.token.renew-
interval=86400000(1 day)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-angular2html&quot;&gt;ERROR JobScheduler: Error running job streaming job 1528366650000 ms.0
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken):
token (token for spark_online: HDFS_DELEGATION_TOKEN owner=spark@XXXXX, renewer=yarn, realUser=, issueDate=1528232733578, maxDate=1528837533578, sequenceNumber=14567778, masterKeyId=1397)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;根據不管是 &lt;a href=&quot;https://spark.apache.org/docs/2.4.6/security.html#long-running-applications&quot;&gt;Spark 2.4.6&lt;/a&gt; 或者 
&lt;a href=&quot;https://spark.apache.org/docs/3.0.0-preview/security.html#long-running-applications&quot;&gt;Spark 3.0.0&lt;/a&gt; 以上的官方介紹文檔，
都表示Spark本身就可以根據使用者提供的keytab和principle去自動的renew token，關鍵句子如下。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;Spark supports automatically creating new tokens for these applications when running in YARN mode. 
Kerberos credentials need to be provided to the Spark application via the spark-submit command, using the --principal and --keytab parameters.
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;但是，HDFS-9276說明，在開啟&lt;a href=&quot;https://codertw.com/程式語言/442243/&quot;&gt;高可用機制的 Hadoop 叢集&lt;/a&gt;上，緩存的 DFSClient 會使用舊的 hdfs_delegation_token 的，從而導致 token 在其最大的生命週期
到達時過期。就是 Spark 在更新 Hadoop HA 叢集的 delegation token 的時候，DFSClient 不會一起更新它的 token (
namenode token)。reference: &lt;a href=&quot;https://www.codenong.com/cs106192404/&quot;&gt;sparkThriftserver 长时间运行HDFS_DELEGATION_TOKEN失效问题&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;解決方法根據 &lt;a href=&quot;https://github.com/apache/spark/pull/9168&quot;&gt;SPARK-11182&lt;/a&gt; 裡面提到的， 可能的方式：&lt;/p&gt;

&lt;p&gt;(1) 更新 Hadoop 的版本到 2.9.0 或以上。（然而我們的版本是 2.6.0，更新的可能性也不大）&lt;/p&gt;

&lt;p&gt;(2) 調整dfs.namenode.delegation.token.max-lifetime 等於一個較大的值，使得 token 最大生命週期變長，從而滿足使用者需要。&lt;/p&gt;

&lt;p&gt;(3) 調整設定 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.hadoop.fs.hdfs.impl.disable.cache=true&lt;/code&gt;。然而，好像沒有效果。&lt;/p&gt;

&lt;p&gt;目前採用的方式是修改 Hadoop Cluster 上面的 token 的 max-lifetime，並在 token 生命週期到達的時候，排程重啟 Spark 
Structured Streaming 程式以更新 token。&lt;/p&gt;

&lt;p&gt;Reference&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/u012150370/article/details/86518366&quot;&gt;记一次HDFS Delegation Token失效问题&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.jianshu.com/p/2904334ae404&quot;&gt;hdfs delegation token 过期问题分析&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.athemaster.com/resources/47&quot;&gt;解釋 Hadoop Delegation Token 上篇&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Thu, 09 Dec 2021 00:00:00 +0000</pubDate>
        <link>/%E6%8A%80%E8%A1%93/2021/12/09/%E8%A8%98%E4%B8%80%E6%AC%A1HDFS_DELEGATION_TOKEN%E9%81%8E%E6%9C%9F%E7%9A%84%E5%95%8F%E9%A1%8C/</link>
        <guid isPermaLink="true">/%E6%8A%80%E8%A1%93/2021/12/09/%E8%A8%98%E4%B8%80%E6%AC%A1HDFS_DELEGATION_TOKEN%E9%81%8E%E6%9C%9F%E7%9A%84%E5%95%8F%E9%A1%8C/</guid>
        
        
        <category>技術</category>
        
      </item>
    
      <item>
        <title>Spark Application with Kerberos - Intro</title>
        <description>&lt;p&gt;Kerberos 是三方認證機制，用戶和服務依賴於第三方（Kerberos 伺服器, KDC）來對彼此進行身份驗證。KDC 包含了一個認證
服務器 (Authenticate Server)，一個票證授權服務器 (Ticket-Granting Server)，以及一個記錄他所知道的 principles
和它們的 Kerberos 密碼的內建資料庫。&lt;/p&gt;

&lt;h3 id=&quot;-principle&quot;&gt;# Principle&lt;/h3&gt;

&lt;p&gt;一個 Kerberos principle 長得像，&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;username/fully.qualified.domain.name@YOUR-REALM.COM，按照先後順序，
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;它們分別是 primary，instance(option) 和 realm。primary 代表 Kerberos 的用戶，它可以是一個 unix account
比如 ap 帳號，也可以是Hadoop服務的Unix帳號，比如 hdfs。instance 是用來區分單個 user 的多個 principle 時使用。
realm 類似 DNS 中的域，不同的是 DNS 是定義了一組主機名，而 realm 則是定義了一組相關的 principle。&lt;/p&gt;

&lt;h3 id=&quot;-keytab&quot;&gt;# Keytab&lt;/h3&gt;

&lt;p&gt;Keytab 包含了加密的principle鍵值和對應的 Kerberos principle。 它被用來在驗證一個 Kerberos principle，
而不用人為得敲打密碼或者明碼保存密碼了。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-angular2html&quot;&gt;A keytab is a file containing pairs of Kerberos principals and encrypted keys (which are derived from the Kerberos password). 
You can use a keytab file to authenticate to various remote systems using Kerberos without entering a password.
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;-ticket-granting-ticket-tgt&quot;&gt;# Ticket-Granting ticket TGT&lt;/h3&gt;
&lt;p&gt;由 KDC 中的 Authenticate Server頒發的票證，使用者帶著這個票證可以向 Server 端請求相應的服務。&lt;/p&gt;

&lt;h3 id=&quot;-ccache-credential-cache&quot;&gt;# ccache (Credential Cache)&lt;/h3&gt;
&lt;p&gt;Credential Cache 也是 Kerberos 驗證身份的一種方式，它持有Kerberos的憑證，使得使用者所執行任務session還有效時，
多次驗證服務器，而不用一直請求 KDC 服務器。&lt;/p&gt;

&lt;h3 id=&quot;-long-running-spark-application-with-kerberos&quot;&gt;# Long-running Spark Application with Kerberos&lt;/h3&gt;

&lt;p&gt;對於一個 Spark Streaming 服務，只要在 spark submit 指令後面加上 –keytab 和 –principle 兩個參數，
Spark 就會幫忙在生命週期終止前，接續的更新 hdfs delegation token 和 login ticket。&lt;/p&gt;

&lt;h4 id=&quot;reference&quot;&gt;Reference&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://mkuthan.github.io/blog/2016/09/30/spark-streaming-on-yarn/&quot;&gt;Long-running Spark Streaming jobs on YARN cluster&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://flume.cn/2016/11/24/Spark踩坑之Streaming在Kerberos的hadoop中renew失敗/值&quot;&gt;Spark踩坑之Streaming在Kerberos的hadoop中renew失敗&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;-kafka-with-a-kerberos-ticket-cache&quot;&gt;# Kafka with a Kerberos Ticket Cache&lt;/h3&gt;

&lt;p&gt;如果你的 Spark Streaming 任務的串流資料來自於 Kafka，別忘了在 worker node 上面，由於 kafka 的 Kerberos 認證 
也會需要的 keytab 會需要送到 worker node 上面，否則會認證失敗。&lt;/p&gt;

&lt;p&gt;jaas_driver.conf&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;KafkaClient {
    com.sun.security.auth.module.Krb5LoginModule required
    useKeyTab=true
    storeKey=true
    keyTab=&quot;/path/on/driver/for/keytab&quot;
    principal=&quot;user@your.customized.realm.name&quot;
    debug=true
    serviceName=&quot;kafka&quot;;
};
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;-kerberos---maximum-renewable-lifetime-for-kerberos-ticket&quot;&gt;# Kerberos - Maximum renewable lifetime for Kerberos Ticket&lt;/h3&gt;

&lt;p&gt;Reference&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://spark.apache.org/docs/2.4.6/running-on-yarn.html#yarn-specific-kerberos-configuration&quot;&gt;Running Spark on YARN&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Sat, 04 Dec 2021 00:00:00 +0000</pubDate>
        <link>/%E6%8A%80%E8%A1%93/2021/12/04/Spark-application-with-Kerberos/</link>
        <guid isPermaLink="true">/%E6%8A%80%E8%A1%93/2021/12/04/Spark-application-with-Kerberos/</guid>
        
        
        <category>技術</category>
        
      </item>
    
      <item>
        <title>踩坑 Azure TFS 部署使用者定義參數</title>
        <description>&lt;h3 id=&quot;前情提要&quot;&gt;前情提要&lt;/h3&gt;

&lt;p&gt;最近在角落研究微軟 Azure TFS 的 Release Pipeline 的參數傳遞的部分，Windows 的 Server 的 Release Pipeline 要讀取部署
Pipeline 上設置的環境變數，到 Linux Server 上面的 shell 做使用。每次覺得 code review 都一切 Look Very Good to
me 的時候，總是會有未知的彩蛋。在 Azure TFS 上設置的環境參數名稱，原本小寫的部分被轉成了大寫，不止如此參數名稱如果原本有帶 dot
的，也轉換成了底線。&lt;/p&gt;

&lt;h3 id=&quot;tfs-release-pipeline-參數名稱命名規範&quot;&gt;TFS Release Pipeline 參數名稱命名規範&lt;/h3&gt;

&lt;p&gt;因為需要把Azure TFS上設置的環境變量，直接帶到 Linux Server 上使用，不想一個一個參數的傳進 shell 檔裡面，參數多的時候真的會覺得
懷疑人生，所以稍微看了一下 Azure Pipeline 的使用者定義參數使用方式。
如果你也想讀英文，這是參考的&lt;a href=&quot;https://docs.microsoft.com/en-us/azure/devops/pipelines/process/variables?view=azure-devops&amp;amp;tabs=yaml%2Cbatch&amp;amp;WT.mc_id=DT-MVP-4015686#variable-naming-restrictions&quot;&gt;連結&lt;/a&gt;。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Macro Syntax Variables&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&quot;language-angular2html&quot;&gt;# 注意這邊是括號不是大括號
echo $(my_variable)
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
  &lt;li&gt;Template Expression Variables&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;範本參數，顧名思義會在編譯的時候就把參數做替換。一般來說，這個參數表達方式，會用在複用部署 YAML 檔的某一部分，並傳遞進去相應的參數。
當發現無法替換的參數，會直接替換成空字串。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Runtime Expression Variables&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;一般來說，這個參數表達方式，會用在條件式判斷去執行不同 Task 的時候。另外，它也只會在作為值的時候被使用，無法作為key值做使用。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-angular2html&quot;&gt;$[variables.key] : value # invalid
key : $[variables.value] # valid
key : $[variables.value]foo # invalid
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;release-pipeline-inline-script-命令行指令的保護措施&quot;&gt;Release Pipeline inline script 命令行指令的保護措施&lt;/h3&gt;

&lt;p&gt;當執行某些重要的指令，比如，登入會使用到的帳號密碼作為參數是不可缺少的部分，如果其中作為密碼的參數不見，很有可能會導致整個 Server 上因為 key 錯
密碼而發生災難。又或者是，在部署期間需要把某個路徑中的文件刪除。如果這個路徑使用環境參數拼出來的話，就會需要特別注意了。一個處理方式是，利用下面的 linux 條件
判斷式，排除某些重要參數為空值的情況。&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-z&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;password&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;+x&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-z&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;account&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;+x&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-z&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;/to/your/app+x&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then
  &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Parameter Error!&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;nb&quot;&gt;exit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;fi&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;或者也有微軟 powershell 的寫法可以參考，&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;PUSH_ACCOUNT&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-And&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;PUSH_PASSWORD&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;c&quot;&gt;# some very important command you want to execute&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  Write-Host &lt;span class=&quot;s2&quot;&gt;&quot;Fatal. Missing Necessary Parameter&quot;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
</description>
        <pubDate>Wed, 17 Nov 2021 00:00:00 +0000</pubDate>
        <link>/%E6%8A%80%E8%A1%93/2021/11/17/%E8%B8%A9%E5%9D%91-Azure-TFS-%E9%83%A8%E7%BD%B2%E4%BD%BF%E7%94%A8%E8%80%85%E8%87%AA%E5%AE%9A%E7%BE%A9%E5%8F%83%E6%95%B8/</link>
        <guid isPermaLink="true">/%E6%8A%80%E8%A1%93/2021/11/17/%E8%B8%A9%E5%9D%91-Azure-TFS-%E9%83%A8%E7%BD%B2%E4%BD%BF%E7%94%A8%E8%80%85%E8%87%AA%E5%AE%9A%E7%BE%A9%E5%8F%83%E6%95%B8/</guid>
        
        
        <category>技術</category>
        
      </item>
    
      <item>
        <title>ELK 監控串流 + Spark Structured Streaming</title>
        <description>&lt;p&gt;之前的做法是，串流數據ETL的結果，寫到Kafka的同時也寫一份到ElasticSearch，這樣就可以在Kibana上面分析串流ETL的效能，但是這樣需要記錄串流數據每一段
的時間戳，才能分析各段即時ETL的耗時。如果系統比較複雜，ETL數據串到最後會有一坨喇股的時間戳，只為了後面的Kibana分析使用。對中間的串流ETL而言都會是多餘的
資源消耗。&lt;/p&gt;

&lt;p&gt;目前讓 logstash 收集各段串流ETL的Kafka topic中的資料，並記錄 CreateTime。再根據event_id在 logstash 進行聚合，
就能計算出平均一筆event，整個串流ETL pipeline所需要的時間。上述是比較細的計算方式，如果只需要簡單的知道每段串流ETL
的效能，也可以只計算TPS(Transaction per seconds)，就是這段pipeline平均每秒處理了多少資料。&lt;/p&gt;

&lt;p&gt;TPS不能真的反應即時串流ETL延遲的情況，也可以理解為一個batch所需要的最小的時間，會是這個即時ETL的最低延遲。
如下說明，如果ETL串流的 Input Rate和Process Rate能保持差不多的速度，表示串流的處理資源足夠。但是，還是會有
因為一個 batch處理了太多的數據，而發生高延遲。解決的方法，是在縮小每個batch的大小和增加更多平行計算的資源，比如更多的
之間 Kafka partitions 或者更多的 Spark CPU core，之間找到平衡點。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Spark Structured Streaming&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Spark Structured Streaming 是一個分佈式即時串流數據處理框架。他使用了 Spark 的 SQL/DataSet/DataFrame API，
開發的人可以輕鬆的實現即時數據的聚合操作和 join 操作，還有窗口化 windowing。&lt;/p&gt;

&lt;p&gt;此外 Spark 3.0 開始，Structured Streaming 提供了一個監控串流ETL的監控 UI。可以清楚地看到，ETL串流的 Input Rate，
Process Rate 等。&lt;/p&gt;
</description>
        <pubDate>Fri, 12 Nov 2021 00:00:00 +0000</pubDate>
        <link>/%E6%8A%80%E8%A1%93/2021/11/12/ELK-%E7%9B%A3%E6%8E%A7%E4%B8%B2%E6%B5%81%E6%95%B8%E6%93%9A/</link>
        <guid isPermaLink="true">/%E6%8A%80%E8%A1%93/2021/11/12/ELK-%E7%9B%A3%E6%8E%A7%E4%B8%B2%E6%B5%81%E6%95%B8%E6%93%9A/</guid>
        
        
        <category>技術</category>
        
      </item>
    
      <item>
        <title>關於提升覺察力，真正接納自我</title>
        <description>&lt;p&gt;好吧，簡單來說上面標題的更白話一點的意思應該是，”慢慢卸下面具，放下想象中的模樣，開始與真正的自己連結。”&lt;/p&gt;

&lt;p&gt;進入職場、大人的世界之後，每天總是會為了迎合他人，而假裝地嘴角上揚，原本你自在的心還會一次次的提醒自己，”你好像已經很久沒有發自內心的笑了”。
直到假裝和表面變成反射動作，你開始對自己不包容、不開放，開始自我批判，下意識地與同儕比較和競爭，怕所有人背著你學習，怕自己不夠好、不夠厲害，甚至害怕
自己沒有別人想像中的那般厲害，於是不自信的思維從心底油然而生，最後誰也無法看清你是誰。接納自我：&lt;/p&gt;

&lt;p&gt;第一步，停止道歉和自我批判。最近工作上和同事聊到想在工作上”做自己”，而不是工作中總是在在”服務他人”，當然如果你從事的是服務業好像就是另當別論。
盤點下來，”做自己”的例子比如，大聲區分工作權責，或者大聲說自己真的想做什麼，而不是不帶感情的完成一件待辦事項。當然這和你富有熱情、熱忱地，想要幫忙解決問題的
情況是完全不同的。熱忱如果不是出自真正接納自己恐會是淪為三分鐘熱度，又或者只是你的其中一個面具。&lt;/p&gt;

&lt;p&gt;第二步，回想自信時刻。自信和自負的區別，打個比方來說就是，你抬起的是下巴還是鼻子，就是你能否接受來自他人的意見或批評。
避免自己在嘗試做自己的時候，迷失方向，看不到其他人，而逃避了其他人，最後在自我逃避。&lt;/p&gt;

&lt;p&gt;第三步，採取行動。找到自己最自在的那個時候，從那開始跨出舒適圈，讓自己去挑戰或爭取心中渴望已久的事物，並將實踐的過程與理想的成果形象化。
清楚地找到自己的目標。&lt;/p&gt;

&lt;p&gt;覺察力，讓你更了解自己，也更容易接納他人，更能夠與他人連結。&lt;/p&gt;
</description>
        <pubDate>Tue, 09 Nov 2021 00:00:00 +0000</pubDate>
        <link>/%E6%9B%B8%E5%B1%8B/2021/11/09/%E9%97%9C%E6%96%BC%E6%8F%90%E5%8D%87%E8%A6%BA%E5%AF%9F%E5%8A%9B-%E7%9C%9F%E6%AD%A3%E6%8E%A5%E7%B4%8D%E8%87%AA%E6%88%91/</link>
        <guid isPermaLink="true">/%E6%9B%B8%E5%B1%8B/2021/11/09/%E9%97%9C%E6%96%BC%E6%8F%90%E5%8D%87%E8%A6%BA%E5%AF%9F%E5%8A%9B-%E7%9C%9F%E6%AD%A3%E6%8E%A5%E7%B4%8D%E8%87%AA%E6%88%91/</guid>
        
        
        <category>書屋</category>
        
      </item>
    
      <item>
        <title>ELK 小白記錄</title>
        <description>&lt;p&gt;ELK是ElasticSearch， Logstash， Kibana三個名詞合在一起的縮寫。 通常用於日誌管理，從集群中的多個service收集日誌，避免開發者直接登入server，
使得生產環境的安全和查找問題的便利性。&lt;/p&gt;

&lt;p&gt;其中，ElasticSearch提供日誌保存，檢索和分析的功能，基於 Apache 
Lucene 真的就是未名覺厲。Logstash收集log並做一些前處理，除了將一些常用的反序列數據的功能變得很好上手，如常見的json，csv。更強大的是， 
grok， dissect 等插件，將非結構化的字符串轉換成結構化的數據， 當然也可以添加或刪除欄位 add_field， 
remove_field。Kibana 則提供資料視覺化的dashboard，直觀的 Kibana Query Language，讓使用者可以更快知道資料的全貌。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Beat and Logstash&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Beats 是一個小型的日誌發送程序的集合，大家最常使用的就是 Filebeat，它能夠將日誌發送到 ELK 集群。除此之外，Beat家族還包括 Packetbeat, 
Metricbeat，Heartbeat，Functionbeat … 等。一般在將日誌文件導入到ElasticSearch進行檢索時，會同時使用 
Filebeat和Logstash，Filebeat負責將服務器上的日誌發送到ELK集群，Logstash則負責將日誌數據轉換成我們需要的格式。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ElasticSearch&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ElasticSearch 和 MongoDB一樣都是NoSQL的資料庫，所有的資料都以JSON格式讀取。不同於傳統的關係型資料庫，文檔和文檔之間的關係會使用 
join來串接，ElasticSearch 通常會用使用sub document的方式。 此外，ElasticSearch 對所有欄位都可以建立索引，並且可以根據不同的用途建立索引。&lt;/p&gt;

</description>
        <pubDate>Sat, 06 Nov 2021 00:00:00 +0000</pubDate>
        <link>/%E6%8A%80%E8%A1%93/2021/11/06/ELK-%E5%B0%8F%E7%99%BD%E8%A8%98%E9%8C%84/</link>
        <guid isPermaLink="true">/%E6%8A%80%E8%A1%93/2021/11/06/ELK-%E5%B0%8F%E7%99%BD%E8%A8%98%E9%8C%84/</guid>
        
        
        <category>技術</category>
        
      </item>
    
      <item>
        <title>logstash聚合同任務的多個事件</title>
        <description>&lt;h3 id=&quot;-前情提要&quot;&gt;# 前情提要&lt;/h3&gt;

&lt;p&gt;前陣子為了監控Spark Structured Streaming的ETL處理時間和TPS等指標，使用logstash接收來自Kafka的event數據，透過Kafka的
時間戳 CreateTime 來記錄資料處理時間，計算source Kafka topic的時間戳和sink端的 Kafka topic 的差值，可以得到這筆
event在ETL的耗時。&lt;/p&gt;

&lt;h3 id=&quot;-aggregation&quot;&gt;# Aggregation&lt;/h3&gt;

&lt;p&gt;由於前端的事件進來Kafka並沒有一個唯一的key值做識別，所以在ETL處理的時候加入了 hash_id 針對整串資料包含時間戳記計算一個唯一值，
讓它可以再後續更複雜的ETL中被識別，算是一個前處理操作。並且，因為需要匯總各個ETL部分的耗時，小小的研究了一下Logstash 聚合事件
的功能的使用方式。可以想到的是，因為是即時串流的事件，資料在不斷的進來，我們幾乎不可能無限時間的等到所有相關的事件都進入 logstash
之後才進行聚合，隨著資料量的增加，對記憶體等硬件的要求也會越來越高，處理效率也會越來越差。所以一個合理的timeout時間設定，或者
合理的事件完成規則的定義就會非常重要了。&lt;/p&gt;

&lt;p&gt;logstash官方對兩種方式都有相關的範例可以參考，aggregation filter的目的是聚合屬於同一任務的多個事件，有對應到前情提要中的場景。
官方舉例的一些應用場景有，&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;任務對事件清楚定義了開始和結束的格式，比如TASK_START或者TASK_END等字樣。&lt;/li&gt;
  &lt;li&gt;沒有定義開始的任務&lt;/li&gt;
  &lt;li&gt;沒有定義結束的任務&lt;/li&gt;
  &lt;li&gt;沒有定義開始，也沒有定義結束&lt;/li&gt;
  &lt;li&gt;沒有定義結束事件，並且將事件在無相關活動狀態超時之後推送&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;-logstash-filter-累加不正確的問題&quot;&gt;# logstash filter 累加不正確的問題&lt;/h3&gt;

&lt;p&gt;logstash對串流資料聚合的支持有一個限制，就是為了要聚合 events 只能使用一個 instance來處理資料，否則會出現奇怪的情況。在官方的
aggregate plugin的文檔上寫道，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;You should be very careful to set Logstash filter workers to 1 (-w 1 flag) 
for this filter to work correctly otherwise events may be processed out of sequence and unexpected results will occur.&lt;/code&gt;
在 pipeline.yml 中需對那個有聚合操作的設定檔，加入 pipeline.workers: 1 ，才能保證聚合插件的正常使用，否則可能會出現數字累加錯誤，
或者事件未收齊就推送的現象。(&lt;a href=&quot;https://www.elastic.co/guide/en/logstash/current/plugins-filters-aggregate.html&quot;&gt;ref&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;Pipeline.workers configuration and aggregation filter&quot;&gt;這篇&lt;/a&gt; 裡面也有說到相關的情況。好在&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pipeline.workers&lt;/code&gt;的預設值就是 1。
所以對於不怎麼思考而是直接使用的人，有一定的防呆機制存在。&lt;/p&gt;
</description>
        <pubDate>Fri, 22 Oct 2021 00:00:00 +0000</pubDate>
        <link>/%E6%8A%80%E8%A1%93/2021/10/22/logstash%E8%81%9A%E5%90%88%E5%90%8C%E4%BB%BB%E5%8B%99%E7%9A%84%E5%A4%9A%E5%80%8B%E4%BA%8B%E4%BB%B6/</link>
        <guid isPermaLink="true">/%E6%8A%80%E8%A1%93/2021/10/22/logstash%E8%81%9A%E5%90%88%E5%90%8C%E4%BB%BB%E5%8B%99%E7%9A%84%E5%A4%9A%E5%80%8B%E4%BA%8B%E4%BB%B6/</guid>
        
        
        <category>技術</category>
        
      </item>
    
  </channel>
</rss>
