<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title></title>
    <description></description>
    <link>/blog/</link>
    <atom:link href="/blog/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Sat, 13 Nov 2021 15:13:24 +0000</pubDate>
    <lastBuildDate>Sat, 13 Nov 2021 15:13:24 +0000</lastBuildDate>
    <generator>Jekyll v4.1.1</generator>
    
      <item>
        <title>ELK 監控串流 + Spark Structured Streaming</title>
        <description>&lt;p&gt;之前的做法是，串流數據ETL的結果，寫到Kafka的同時也寫一份到ElasticSearch，這樣就可以在Kibana上面分析串流ETL的效能，但是這樣需要記錄串流數據每一段
的時間戳，才能分析各段即時ETL的耗時。如果系統比較複雜，ETL數據串到最後會有一坨喇股的時間戳，只為了後面的Kibana分析使用。對中間的串流ETL而言都會是多餘的
資源消耗。&lt;/p&gt;

&lt;p&gt;目前讓 logstash 收集各段串流ETL的Kafka topic中的資料，並記錄 CreateTime。再根據event_id在 logstash 進行聚合，
就能計算出平均一筆event，整個串流ETL pipeline所需要的時間。上述是比較細的計算方式，如果只需要簡單的知道每段串流ETL
的效能，也可以只計算TPS(Transaction per seconds)，就是這段pipeline平均每秒處理了多少資料。&lt;/p&gt;

&lt;p&gt;TPS不能真的反應即時串流ETL延遲的情況，也可以理解為一個batch所需要的最小的時間，會是這個即時ETL的最低延遲。
如下說明，如果ETL串流的 Input Rate和Process Rate能保持差不多的速度，表示串流的處理資源足夠。但是，還是會有
因為一個 batch處理了太多的數據，而發生高延遲。解決的方法，是在縮小每個batch的大小和增加更多平行計算的資源，比如更多的
之間 Kafka partitions 或者更多的 Spark CPU core，之間找到平衡點。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Spark Structured Streaming&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Spark Structured Streaming 是一個分佈式即時串流數據處理框架。他使用了 Spark 的 SQL/DataSet/DataFrame API，
開發的人可以輕鬆的實現即時數據的聚合操作和 join 操作，還有窗口化 windowing。&lt;/p&gt;

&lt;p&gt;此外 Spark 3.0 開始，Structured Streaming 提供了一個監控串流ETL的監控 UI。可以清楚地看到，ETL串流的 Input Rate，
Process Rate 等。&lt;/p&gt;
</description>
        <pubDate>Fri, 12 Nov 2021 00:00:00 +0000</pubDate>
        <link>/blog/%E6%8A%80%E8%A1%93/2021/11/12/ELK-%E7%9B%A3%E6%8E%A7%E4%B8%B2%E6%B5%81%E6%95%B8%E6%93%9A.html</link>
        <guid isPermaLink="true">/blog/%E6%8A%80%E8%A1%93/2021/11/12/ELK-%E7%9B%A3%E6%8E%A7%E4%B8%B2%E6%B5%81%E6%95%B8%E6%93%9A.html</guid>
        
        
        <category>技術</category>
        
      </item>
    
      <item>
        <title>關於提升覺察力，真正接納自我</title>
        <description>&lt;p&gt;好吧，簡單來說上面標題的更白話一點的意思應該是，”慢慢卸下面具，放下想象中的模樣，開始與真正的自己連結。”&lt;/p&gt;

&lt;p&gt;進入職場、大人的世界之後，每天總是會為了迎合他人，而假裝地嘴角上揚，原本你自在的心還會一次次的提醒自己，”你好像已經很久沒有發自內心的笑了”。
直到假裝和表面變成反射動作，你開始對自己不包容、不開放，開始自我批判，下意識地與同儕比較和競爭，怕所有人背著你學習，怕自己不夠好、不夠厲害，甚至害怕
自己沒有別人想像中的那般厲害，於是不自信的思維從心底油然而生，最後誰也無法看清你是誰。接納自我：&lt;/p&gt;

&lt;p&gt;第一步，停止道歉和自我批判。最近工作上和同事聊到想在工作上”做自己”，而不是工作中總是在在”服務他人”，當然如果你從事的是服務業好像就是另當別論。
盤點下來，”做自己”的例子比如，大聲區分工作權責，或者大聲說自己真的想做什麼，而不是不帶感情的完成一件待辦事項。當然這和你富有熱情、熱忱地，想要幫忙解決問題的
情況是完全不同的。熱忱如果不是出自真正接納自己恐會是淪為三分鐘熱度，又或者只是你的其中一個面具。&lt;/p&gt;

&lt;p&gt;第二步，回想自信時刻。自信和自負的區別，打個比方來說就是，你抬起的是下巴還是鼻子，就是你能否接受來自他人的意見或批評。
避免自己在嘗試做自己的時候，迷失方向，看不到其他人，而逃避了其他人，最後在自我逃避。&lt;/p&gt;

&lt;p&gt;第三步，採取行動。找到自己最自在的那個時候，從那開始跨出舒適圈，讓自己去挑戰或爭取心中渴望已久的事物，並將實踐的過程與理想的成果形象化。
清楚地找到自己的目標。&lt;/p&gt;

&lt;p&gt;覺察力，讓你更了解自己，也更容易接納他人，更能夠與他人連結。&lt;/p&gt;
</description>
        <pubDate>Tue, 09 Nov 2021 00:00:00 +0000</pubDate>
        <link>/blog/%E7%94%9F%E6%B4%BB/2021/11/09/%E9%97%9C%E6%96%BC%E6%8F%90%E5%8D%87%E8%A6%BA%E5%AF%9F%E5%8A%9B-%E7%9C%9F%E6%AD%A3%E6%8E%A5%E7%B4%8D%E8%87%AA%E6%88%91.html</link>
        <guid isPermaLink="true">/blog/%E7%94%9F%E6%B4%BB/2021/11/09/%E9%97%9C%E6%96%BC%E6%8F%90%E5%8D%87%E8%A6%BA%E5%AF%9F%E5%8A%9B-%E7%9C%9F%E6%AD%A3%E6%8E%A5%E7%B4%8D%E8%87%AA%E6%88%91.html</guid>
        
        
        <category>生活</category>
        
      </item>
    
      <item>
        <title>ELK 小白記錄</title>
        <description>&lt;p&gt;ELK是ElasticSearch， Logstash， Kibana三個名詞合在一起的縮寫。 通常用於日誌管理，從集群中的多個service收集日誌，避免開發者直接登入server，
使得生產環境的安全和查找問題的便利性。&lt;/p&gt;

&lt;p&gt;其中，ElasticSearch提供日誌保存，檢索和分析的功能，基於 Apache 
Lucene 真的就是未名覺厲。Logstash收集log並做一些前處理，除了將一些常用的反序列數據的功能變得很好上手，如常見的json，csv。更強大的是， 
grok， dissect 等插件，將非結構化的字符串轉換成結構化的數據， 當然也可以添加或刪除欄位 add_field， 
remove_field。Kibana 則提供資料視覺化的dashboard，直觀的 Kibana Query Language，讓使用者可以更快知道資料的全貌。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Beat and Logstash&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Beats 是一個小型的日誌發送程序的集合，大家最常使用的就是 Filebeat，它能夠將日誌發送到 ELK 集群。除此之外，Beat家族還包括 Packetbeat, 
Metricbeat，Heartbeat，Functionbeat … 等。一般在將日誌文件導入到ElasticSearch進行檢索時，會同時使用 
Filebeat和Logstash，Filebeat負責將服務器上的日誌發送到ELK集群，Logstash則負責將日誌數據轉換成我們需要的格式。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ElasticSearch&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ElasticSearch 和 MongoDB一樣都是NoSQL的資料庫，所有的資料都以JSON格式讀取。不同於傳統的關係型資料庫，文檔和文檔之間的關係會使用 
join來串接，ElasticSearch 通常會用使用sub document的方式。 此外，ElasticSearch 對所有欄位都可以建立索引，並且可以根據不同的用途建立索引。&lt;/p&gt;

</description>
        <pubDate>Sat, 06 Nov 2021 00:00:00 +0000</pubDate>
        <link>/blog/%E6%8A%80%E8%A1%93/2021/11/06/ELK-%E5%B0%8F%E7%99%BD%E8%A8%98%E9%8C%84.html</link>
        <guid isPermaLink="true">/blog/%E6%8A%80%E8%A1%93/2021/11/06/ELK-%E5%B0%8F%E7%99%BD%E8%A8%98%E9%8C%84.html</guid>
        
        
        <category>技術</category>
        
      </item>
    
  </channel>
</rss>
