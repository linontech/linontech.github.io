---
layout: post
title: "ELK 監控串流 + Spark Structured Streaming"
subtitle: ""
date: 2021-11-12
categories: [技術]
---

之前的做法是，串流數據ETL的結果，寫到Kafka的同時也寫一份到ElasticSearch，這樣就可以在Kibana上面分析串流ETL的效能，但是這樣需要記錄串流數據每一段
的時間戳，才能分析各段即時ETL的耗時。如果系統比較複雜，ETL數據串到最後會有一坨喇股的時間戳，只為了後面的Kibana分析使用。對中間的串流ETL而言都會是多餘的
資源消耗。

目前讓 logstash 收集各段串流ETL的Kafka topic中的資料，並記錄 CreateTime。再根據event_id在 logstash 進行聚合，
就能計算出平均一筆event，整個串流ETL pipeline所需要的時間。上述是比較細的計算方式，如果只需要簡單的知道每段串流ETL
的效能，也可以只計算TPS(Transaction per seconds)，就是這段pipeline平均每秒處理了多少資料。

TPS不能真的反應即時串流ETL延遲的情況，也可以理解為一個batch所需要的最小的時間，會是這個即時ETL的最低延遲。
如下說明，如果ETL串流的 Input Rate和Process Rate能保持差不多的速度，表示串流的處理資源足夠。但是，還是會有
因為一個 batch處理了太多的數據，而發生高延遲。解決的方法，是在縮小每個batch的大小和增加更多平行計算的資源，比如更多的
之間 Kafka partitions 或者更多的 Spark CPU core，之間找到平衡點。

- Spark Structured Streaming

Spark Structured Streaming 是一個分佈式即時串流數據處理框架。他使用了 Spark 的 SQL/DataSet/DataFrame API，
開發的人可以輕鬆的實現即時數據的聚合操作和 join 操作，還有窗口化 windowing。

此外 Spark 3.0 開始，Structured Streaming 提供了一個監控串流ETL的監控 UI。可以清楚地看到，ETL串流的 Input Rate，
Process Rate 等。
