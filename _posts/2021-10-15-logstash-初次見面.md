---
layout: post
title: "logstash 初次見面"
subtitle: ""
date: 2021-10-15
categories: [技術]
---

Logstash: Collect, Parse and Transform logs. 

Logstash 是一個用來做日誌收集，分析，過濾的工具。一開始就是見到了，
logstash的資料流的設定檔案，名稱前面標示了數字，聽前說人檔案會按照 filename 字母順序組合，這在需要切分複雜設定的時候
或許有些用，也要特別注意用條件來區分不同的資料流。但使用下來我還是覺得如果沒有需要幾千行的設定，那還是放在一個設定檔裡面就好了。

### # 設定檔格式

input, filter, output 的組成非常符合 Logstash 的人設。要特別說的是檔案裡面也是可以空行和寫注釋的，
畢竟只是一個定義資料流的腳本，寫明白資料的來源格式和指定輸出格式，以及解析的方式還是很重要的。

```
input { # comments can appear at the end of a line, too
  http {
    codec => json {
      charset => "ISO-8859-1"
      target => "[document]"
    }
  }
}

filter {
}

output {
}
```

### # 常用的 plugin

#### codec

codec 表示編解碼插件，可以按照約定好的格式將數據讀進來logstash。例如直接將json字符串格式的資料定義為key value的格式。
一些常見的編解碼插件如下，

(1) json
(2) csv
(3) protobuf 

Google Protocol Buffer 是一種輕便高效的結構化存儲數據的格式。

(4) multiline

Collapse multiline messages and merge them into a single event. 例如，當你需要將任何一行不是以時間戳記
開頭的字符串合併到它的上一行，就可以很方便的使用這個 codec。官方給的實現方式如下，

```
    input {
      file {
        path => "/var/log/someapp.log"
        codec => multiline {
          # Grok pattern names are valid! :)
          pattern => "^%{TIMESTAMP_ISO8601} "
          negate => true
          what => "previous"
        }
      }
    }
```


(5) rubydebug

輸出時使用，通常會用在 debug 的時候。它能將logstash的事件用Ruby Amazing Print library的格式輸出。

#### grok

grok 是一個 filter 插件，負責把收到的數據，以使用者自定義的正則處理，讓數據變成使用者想要的鍵值對的格式。

特別的，由於日誌通常很長一串又格式複雜，於是 [Grok Debugger Tool](https://grokdebug.herokuapp.com) 就出現了，
可以直接透過這個小工具來檢查自己的解析語法是否match到所有自己想要的欄位。
