---
layout: post
title: "Kafka!"
subtitle: ""
date: 2021-09-05
categories: [技術]
---

[TOC]

## Table of Kafka

1. Kafka 特點
2. Kafka 名詞解釋
3. 建置 Kafka 環境和相關設定
4. Kafka 生態圈
5. How to parallelize Consumer ?

## Kafka 基本介紹

Kafka 是Linkedin公司開始後來由Apache基金會開發的一個分佈式，支持多分區、多副本的資料流處理平台，他同時也是一個基於
發佈和訂閱的消息隊列系統。常用來處理，異步處理請求、流量削峰、日誌處理、解耦業務處理過程等場景。它基於 Java 和 Scala 語言開發。
它的一些流處理(Stream processing capabilities)特性：

- 高吞吐 低延遲：Kafka 的最大的優點就是收發消息特別快，每秒可以處理幾十萬比數據
- 高並發 可拓展性：Kafka 是分佈式系統 distributed system，可以彈性縮放所需的資源，處理不同場景的串流數據。一個 topic 
可以有多個分區，分佈在不同的 broker 上。多個 partition 可以讓多個客戶端同時讀寫。
- 資料持久化 可靠性：Kafka 可以將數據持久化存儲，數據被保存成 bytearray 的格式，並在 consume 的時候在被反序列化成
可讀的格式(string, json, ...)
- 容錯性：Kafka 提供了三種 delivery guarantees: At most once, At least once, Exactly once

生產消息的 Producer，和消費者 Consumer/Consumer Group，兩端業務邏輯被解耦：一個負責生產數據，另一個就是單純
把數據接收下來，並且由 Consumer Group 去記錄對應某個 Topic 目前信息接收到第幾條了(offset)。這些生產者和
消費者彼此之間除了約定 Schema 之外沒有直接的關聯，生產者和消費者的活動都由 Kafka Broker 負責。
可以說一個 Kafka Broker 就是一個 Kafka ，多個 Kafka Broker 就會組成一個 Kafka 集群。

## Kafka 名詞解釋

- Event: 每個在 Kafka 內保存的資料可以視為一個事件，一個事件包含了鍵 key，值 value，時間戳 timestamp。

- Topic: 區分不同消息的放置位置和，好比 table name。

- Partition: 分區，這裡的概念基本上和 ElasticSearch 上的分片概念是一樣的。都是想把數據合理的放在不同 server 的分區上面，
以達到負載均衡。特別要注意的是，每個分區存儲的數據都是有序的，但是不同分區間的數據不保證有序性。若有保證有序，
那就只能設置一個分區。

- Replica: 副本，kafka 為了防止服務器壞掉採取的措施。需要注意的是不同分區的備份存放的是不同部分的數據，也就是如果沒有備份整個
kafka 集群就無法備份 kafka topic 的所有的分區。

- Broker: Broker 指運行 Kafka 的機器。多個 Broker 就組成 Kafka 集群。

- Controller(Leader Broker): Kafka controller 是一個 Kafka集群的頭腦部分，一個Kafka集群只能有一個 Controller，那個節點就和一般的broker無異，
只是多負責管理整個集群中所有分區和副本的狀態，比如 broker server 的上線、下線處理，創建/刪除 topic，處理每個 topic 的分區副本分配，以及 leader
的選舉，等等。

- Zookeeper

提到 Controller 就感覺還會需要科普學習一下 Zookeeper。官方文件寫到，
`ZooKeeper is a centralized service for maintaining configuration information, naming,
 providing distributed synchronization, and providing group services. `
至少在 2021 年之前他對於 Kafka 都扮演重要的角色。Kafka 保存了很多重要的元數據在 Zookeeper，比如 Kafka topic 的基本資訊，分區、副本等資訊，
以及 Broker 信息和ISR（In-Sync Replicas）等等。

- ISR (In-Sync-replicas): Isr 表示目前 in-sync 的 replicas，如果目前 broker 的連接及運作均正常，Isr 就等同於 replicas。可以在 topic 的
describe 資訊中確認。

- Consumer Group: 將 Consumer 註冊在指定的 group id 下，那他就會被分配到一個 Consumer Group，同一個 group 
裡面的 Consumer 不會收到相同的資料。

- Offset: 記錄 consumer group 在每個 kafka topic 的每個分區的索引。
  `offset is an indexed maintained at __consumer_offset topic for each consumer group id, topic name and partition number.`

- Lag: consumer group 的未讀新消息數量。

## Kafka 歷史版本

Kafka 最初是由領英開發，然後開源成為 Apache Kafka，之後領英的員工們成立了 Confluent，在開源軟體的基礎上加強。
Apache Kafka 的版本號演進，分別是 0.7.x.x, 0.8.x.x, 0.9.x.x, 0.10.x.x, 0.11.x.x, 1.x.x, 2.x.x, 目前比較新的版本是
2.4.0。整理一些比較重要的版本更新里程碑，雖然可以直接選最新最穩定的版本就好了，但是了解里程碑也可以間接理解，社群在發展 Kafka 的
重點，以及舊版本的 Kafka 的不足之處和新版本的炫酷功能。

- 0.7.x.x, 0.8.x.x : 這兩個是非常老的 Kafka 版本，要看到它們至少也要是5年沒有更新的系統了，原則上非常不建議使用，因為有很多的功能都是它們不支持的。

- 0.9.x.x : 加入了很多安全方面的支持，比如 Kerberos 認證機制、數據加密和授權管理等等。加入 Kafka Connect 的功能。

- 0.10.x.x : 加入 Kafka Stream 的功能，使得 Kafka 不再只是個消息隊列，而是一個資料流處理平台。

- 0.11.x.x : Kafka 從 0.11.x.x 版本開始支持 Exactly-Once。主要原因是因為實現了資料生產端 Producer 端的冪等性和事務特性。另外，這個版本也對信息格
式做了重構。

- 1.x.x : 改進 Kafka Connect 和 Kafka Stream 的功能。另外也實現了磁碟的故障處理，Broker 內的某個磁碟壞掉時它會將數據轉移到其他磁碟上，而不會導致
整台 Broker 停止工作。以及 Kafka 資料分區的副本可以在同一台 Broker 的不同磁碟上移動，優化了對磁碟的負載。

- 2.x.x : 繼續改進 Kafka Connect 和 Kafka Stream。壓縮 Kafka 保存在磁碟上的數據，同時也減少網路的IO消耗。


## Kafka 生態圈

Kafka Stream: 從 Apache Kafka 0.10 版本開始引入的一個 [feature]
(https://kafka.apache.org/0102/javadoc/index.html?org/apache/kafka/streams/KafkaStreams.html)。
他是用於流計算的lib，和 Spark Streaming，Storm，Flink 等類似。

Kafka Connect: 一個介接其他數據庫和 Kafka 之間的串流工具，它繼承了 Kafka 的可擴展性(scalability)和高可靠性(reliably)
。它可以接收整個數據庫，比如 Oracle，或者收集特定的指標，送到指定的 Kafka topic。


## 建置 Kafka 環境和相關設定

通常 Kafka 集群都會和 ZooKeeper 綁定，ZooKeeper 作為一個分佈式資源的集中服務扮演者協調 Kafka Server 的角色，每個 Kafka Broker 都會到 ZooKeeper 註冊。

1. 選擇版本並從官網安裝 https://downloads.apache.org/kafka/
2. 設定 listeners 服務器真正 bind 的地址和 advertised.listeners，曝露給外部的 ip 地址，如果沒有設定的話會
   直接使用 listeners 。他們告訴 Kafka 的客戶端要用什麼協議，哪個 ip 地址去訪問 Kafka 服務。通常在內網部署 Kafka 是不會用到 advertised.listners 的，
   只有在 Docker 或在雲服務集群上部署會用到。

```angular2html
e.g. 
listeners=PLAINTEXT://HOSTNAME:PORT,SSL://HOSTNAME:PORT

advertised.listeners=INSIDE://HOSTNAME:PORT,OUTSIDE://HOSTNAME:PORT
listener.security.protocol.map=INSIDE:SASL_PLAINTEXT,OUTSIDE:SASL_PLAINTEXT

P.S 
PLAINTEXT 代表 listeners 不需要授權或者加密
SASL_PLAINTEXT 代表需要 SASL 授權，但是不加密
SASL_SSL 代表 SASL 授權且使用 SSL 加密通訊
SSL 使用 SSL 加密通訊
```

## 如何設定 Kafka Topic 的參數才能最佳資料流處理性能?

How to Parallelize Kafka Consumer ?

使用 Kafka 設定資料流時最常會遇到的問題，即要如何設定 Kafka topic 的分區數和備份個數，以及要使用多少個 consumer
去讀取資料才能最佳化資料流性能？這篇[文章](https://medium.com/@jhansireddy007/how-to-parallelise-kakfa-consumers-59c8b0bbc37a)
裡有淺顯易懂的舉例。在同一個 Consumer Group 裡面的兩個 Consumer 不會分配到一個 Kafka topic 的同一個 Partition。
同理，一份資料不會被一個 Consumer Group 裡面的多個 Consumer 處理。

如果有一個 Consumer Group 裡有4個 Consumer 對應某個 Kafka topic 的四個 Partition。此時，再新加入一個 Consumer
將不會優化並行處理的性能，新加入的 consumer 會是 idle 的狀態。一個 consumer 可以分配到多個 Partition，但是一個 Partition
不能分配給多個 Consumer。Kafka Partition 只在同一個 Consumer Group 裡的多個 Consumer 間分配。
`Kafka can’t assign the same partition to two consumers within the same group.` 所以 Consumer Group 裡的
最佳 Consumer 個數就是一個 Kafka topic 的分區個數。


## Reference

1. [Kafka Consumers: Reading Data From Kafka](https://www.oreilly.com/library/view/kafka-the-definitive/9781491936153/ch04.html)
2. [How to parallelise Kafka consumers](https://medium.com/@jhansireddy007/how-to-parallelise-kafka-consumers-59c8b0bbc37a)
