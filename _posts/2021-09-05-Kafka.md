---
layout: post
title: "Kafka!"
subtitle: ""
date: 2021-09-05
categories: [技術]
---

[TOC]

## Table of Kafka

1. Kafka 基本介紹
2. Kafka 名詞解釋
3. 建置 Kafka 環境和相關設定
4. Kafka 生態圈
5. How to parallelize Consumer ?

## Kafka 基本介紹

Kafka 是Linkedin公司開始後來由Apache基金會開發的一個分佈式，支持多分區、多副本的資料流處理平台，他同時也是一個基於
發佈和訂閱的消息隊列系統。常用來異步處理請求、流量削峰、日誌處理、解耦業務處理過程。。等等。它基於Java和Scala語言開發。
它的一些流處理(Stream processing capabilities)特性：

- 高吞吐 低延遲：Kafka 的最大的優點就是收發消息特別快，每秒可以處理幾十萬比數據
- 高並發 可拓展性：Kafka 是分佈式系統 distributed system，可以彈性縮放所需的資源，處理不同場景的串流數據。一個 topic 
可以有多個分區，分佈在不同的 broker 上。多個 partition 可以讓多個客戶端同時讀寫。
- 資料持久化 可靠性：Kafka 可以將數據持久化存儲，數據被保存成 bytearray 的格式，並在 consume 的時候在被反序列化成
可讀的格式(string, json, ...)
- 容錯性：Kafka 提供了三種 delivery guarantees: At most once, At least once, Exactly once

生產消息的 Producer，和消費者 Consumer/Consumer Group，兩端業務邏輯被解耦：一個負責生產數據，另一個就是單純
把數據接收下來，並且由 Consumer Group去記錄對應某個 Topic 目前信息接收到第幾條了(offset)。這些生產者和
消費者彼此之間除了約定 Schema 之外沒有直接的關聯，生產者和消費者的活動都由 kafka broker 負責。
可以說一個 kafka broker 就是一個 kafka ，多個 kafka broker 就會組成一個 kafka 集群。

## 名詞解釋

- Event: 每個在 Kafka 內保存的資料可以視為一個事件，一個事件包含了鍵 key，值 value，時間戳 timestamp。

- Topic: 區分不同消息的放置位置和，好比 table name。

- Partition: 分區，這裡的概念基本上和 ElasticSearch 上的分片概念是一樣的。都是想把數據合理的放在不同 server 的分區上面，
以達到負載均衡。特別要注意的是，每個分區存儲的數據都是有序的，但是不同分區間的數據不保證有序性。若有保證有序，
那就只能設置一個分區。

- Replica: 副本，kafka 為了防止服務器壞掉採取的措施。需要注意的是不同分區的備份存放的是不同部分的數據，也就是如果沒有備份整個
kafka 集群就無法備份 kafka topic 的所有的分區。

- Broker: Broker 指運行 Kafka 的機器。多個 Broker 就組成 Kafka 集群。

- Controller(Leader Broker): Kafka controller 是一個 Kafka集群的頭腦部分，一個Kafka集群只能有一個 Controller，那個節點就和一般的broker無異，
只是多負責管理整個集群中所有分區和副本的狀態，比如 broker server 的上線、下線處理，創建/刪除 topic，處理每個 topic 的分區副本分配，以及 leader
的選舉，等等。

- Zookeeper

提到 Controller 就感覺還會需要科普學習一下下 zookeeper。官方文件寫到，
`ZooKeeper is a centralized service for maintaining configuration information, naming,
 providing distributed synchronization, and providing group services. `
至少在 2021 年之前他對於 kafka都扮演重要的角色。 
Kafka 保存了很多重要的元數據在 zookeeper，比如 kafka topic 的基本資訊，分區、副本等資訊，
以及 broker 信息和ISR（In-Sync Replicas）等等。

- ISR (In-Sync-replicas): Isr 表示目前 in-sync 的 replicas，如果目前 broker 的連接及運作均正常，Isr 就等同於 replicas。可以在 topic 的
describe 資訊中確認。

- Offset: 記錄每個 consumer group 在每個 kafka topic 的每個分區的索引。
`offset is an indexed maintained at __consumer_offset topic for each consumer group id, topic name and partition number.`

- Consumer group: 將 Consumer 註冊在指定的 group id 下，那他就會被分配到一個 consumer group，同一個 group 
裡面的 consumer 不會收到相同的資料。

- Lag: consumer group 的未讀新消息數量。


## 建置 Kafka 環境和相關設定

通常 Kafka 集群都會和 ZooKeeper 綁定，ZooKeeper 作為一個分佈式資源的集中服務扮演者協調 Kafka Server 的角色，
每個 Kafka broker 都會到 ZooKeeper 註冊。

1. 選擇版本並從官網安裝 https://downloads.apache.org/kafka/
2. 設定 listeners 服務器真正 bind 的地址和 advertised.listeners，曝露給外部的 ip 地址，如果沒有設定的話會
   直接使用 listeners 。他們告訴 Kafka 的客戶端要用什麼協議，哪個 ip 地址去訪問 Kafka 服務。

```angular2html
e.g. 
listeners=PLAINTEXT://HOSTNAME:PORT,SSL://HOSTNAME:PORT

listeners=INSIDE://HOSTNAME:PORT,OUTSIDE://HOSTNAME:PORT
listener.security.protocol.map=INSIDE:SASL_PLAINTEXT,OUTSIDE:SASL_PLAINTEXT

P.S 
PLAINTEXT 代表 listeners 不需要授權或者加密
SASL_PLAINTEXT 代表需要 SASL 授權，但是不加密
SASL_SSL 代表 SASL 授權且使用 SSL 加密通訊
SSL 使用 SSL 加密通訊
```

## Kafka 生態圈

Kafka Stream: 從 Apache Kafka 0.10 版本開始引入的一個 [feature]
(https://kafka.apache.org/0102/javadoc/index.html?org/apache/kafka/streams/KafkaStreams.html)。
他是用於流計算的lib，和 Spark Streaming，Storm，Flink 等類似。

Kafka Connect: 一個介接其他數據庫和 Kafka 之間的串流工具，它繼承了 Kafka 的可擴展性(scalability)和高可靠性(reliably)
。它可以接收整個數據庫，比如 Oracle，或者收集特定的指標，送到指定的 Kafka topic。


## How to Parallelize Kafka Consumer ?

使用 Kafka 設定資料流時最常會遇到的問題，即要如何設定 kafka topic 的分區數和備份個數，以及要使用多少個 consumer
去讀取資料才能最佳化資料流性能？這篇[文章](https://medium.com/@jhansireddy007/how-to-parallelise-kakfa-consumers-59c8b0bbc37a)
裡有淺顯易懂的舉例。在同一個 consumer group 裡面的兩個 consumer 不會分配到一個 kafka topic 的同一個 partition。
同理，一份資料不會被一個 consumer group 裡面的多個 consumer 處理。

如果有一個 consumer group 裡有4個 consumer 對應某個 kafka topic 的四個 partition。此時，再新加入一個 consumer
將不會優化並行處理的性能，新加入的 consumer 會是 idle 的狀態。一個 consumer 可以分配到多個 partition，但是一個 partition
不能分配給多個 consumer。Kafka partition 只在同一個 consumer group 裡的多個 consumer 間分配。
`Kafka can’t assign the same partition to two consumers within the same group.` 所以 consumer group 裡的
最佳 consumer 個數就是一個 kafka topic 的分區個數。


## Reference

1. [Kafka Consumers: Reading Data From Kafka](https://www.oreilly.com/library/view/kafka-the-definitive/9781491936153/ch04.html)
2. [How to parallelise Kafka consumers](https://medium.com/@jhansireddy007/how-to-parallelise-kafka-consumers-59c8b0bbc37a)
